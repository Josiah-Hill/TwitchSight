{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/VS Code Projects/TwitchSight/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_classes = {0: 'Account Management', 1: 'Ads', 2: 'Badges/Emotes', 3: 'Bits', 4: 'Channel Page', 5: 'Channel Points', 6: 'Charity', 7: 'Chat', 8: 'Creator Camp', 9: 'Creator Dashboard', 10: 'Creator Dashboard: Stream Manager', 11: 'Creators and Stream Features', 12: 'Customer Experience', 13: 'Developers', 14: 'Discover', 15: 'Extensions', 16: 'IGDB', 17: 'IRL Events and Merch', 18: 'Localization', 19: 'Moderation', 20: 'Purchase Management', 21: 'Safety', 22: 'Subscriptions', 23: 'Twitch Applications: Consoles', 24: 'Twitch Applications: Mobile', 25: 'Twitch Applications: TV Apps', 26: 'Twitch Studio', 27: 'User Accessibility', 28: 'Video Features', 29: 'Video Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NN_CLF_GPT(nn.Module):\n",
    "    def __init__(self, input_size=1536, output_size=30):\n",
    "        super(NN_CLF_GPT, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "class NN_CLF_BERT(nn.Module):\n",
    "    def __init__(self, input_size=384, output_size=30):\n",
    "        super(NN_CLF_BERT, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "class NN_REG_GPT(nn.Module):\n",
    "    def __init__(self, input_size=1536):\n",
    "        super(NN_REG_GPT, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)  # Output size is 1 for regression\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "class NN_REG_BERT(nn.Module):\n",
    "    def __init__(self, input_size=384):\n",
    "        super(NN_REG_BERT, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)  # Output size is 1 for regression\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    " \n",
    "class NN_REGSIF_GPT(nn.Module):\n",
    "    def __init__(self, input_size=1536, num_classes=30):\n",
    "        super(NN_REGSIF_GPT, self).__init__()\n",
    "        # Shared layers\n",
    "        self.base_layer1 = nn.Linear(input_size, 128)\n",
    "        self.base_layer2 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Regression head\n",
    "        self.regression_head = nn.Linear(64, 1)  # Output one value for regression\n",
    "\n",
    "        # Classification head\n",
    "        self.classification_head = nn.Linear(64, num_classes)  # Output for each class\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shared layers\n",
    "        x = self.relu(self.base_layer1(x))\n",
    "        x = self.relu(self.base_layer2(x))\n",
    "\n",
    "        # Regression and classification heads\n",
    "        regression_output = self.regression_head(x)\n",
    "        classification_output = self.classification_head(x)\n",
    "\n",
    "        return regression_output, classification_output\n",
    "       \n",
    "class NN_REGSIF_BERT(nn.Module):\n",
    "    def __init__(self, input_size=384, num_classes=30):\n",
    "        super(NN_REGSIF_BERT, self).__init__()\n",
    "        # Shared layers\n",
    "        self.base_layer1 = nn.Linear(input_size, 128)\n",
    "        self.base_layer2 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Regression head\n",
    "        self.regression_head = nn.Linear(64, 1)  # Output one value for regression\n",
    "\n",
    "        # Classification head\n",
    "        self.classification_head = nn.Linear(64, num_classes)  # Output for each class\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shared layers\n",
    "        x = self.relu(self.base_layer1(x))\n",
    "        x = self.relu(self.base_layer2(x))\n",
    "\n",
    "        # Regression and classification heads\n",
    "        regression_output = self.regression_head(x)\n",
    "        classification_output = self.classification_head(x)\n",
    "\n",
    "        return regression_output, classification_output\n",
    "    \n",
    "nn_clf_gpt = NN_CLF_GPT()\n",
    "nn_clf_bert = NN_CLF_BERT()\n",
    "nn_reg_gpt = NN_REG_GPT()\n",
    "nn_reg_bert = NN_REG_BERT()\n",
    "nn_regsif_gpt = NN_REGSIF_GPT()\n",
    "nn_regsif_bert = NN_REGSIF_BERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models loaded.\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "ml_model_names, dl_model_names = [], []\n",
    "for model_name in os.listdir('models/'):\n",
    "    model_first_name = model_name.split('.')[0]\n",
    "    if '.pkl' == model_name[-4:] or '.pickle' in model_name[-7:]:\n",
    "        ml_model_names.append(model_first_name)\n",
    "        with open(f'models/{model_name}', 'rb') as f:\n",
    "            models[model_first_name] = pickle.load(f)\n",
    "    elif '.pt' == model_name[-3:] or '.pth' in model_name[-4:]:\n",
    "        dl_model_names.append(model_first_name)\n",
    "        if model_first_name == 'neural_network_classification_GPT':\n",
    "            nn_clf_gpt.load_state_dict(torch.load(f'models/{model_name}'))\n",
    "            models[model_first_name] = nn_clf_gpt.to('cpu').eval()\n",
    "        if model_first_name == 'neural_network_classification_BERT':\n",
    "            nn_clf_bert.load_state_dict(torch.load(f'models/{model_name}'))\n",
    "            models[model_first_name] = nn_clf_bert.to('cpu').eval()\n",
    "        if model_first_name == 'neural_network_regression_GPT':\n",
    "            nn_reg_gpt.load_state_dict(torch.load(f'models/{model_name}'))\n",
    "            models[model_first_name] = nn_reg_gpt.to('cpu').eval()\n",
    "        if model_first_name == 'neural_network_regression_BERT':\n",
    "            nn_reg_bert.load_state_dict(torch.load(f'models/{model_name}'))\n",
    "            models[model_first_name] = nn_reg_bert.to('cpu').eval()\n",
    "        if model_first_name == 'regsification_GPT':\n",
    "            nn_regsif_gpt.load_state_dict(torch.load(f'models/{model_name}'))\n",
    "            models[model_first_name] = nn_regsif_gpt.to('cpu').eval()\n",
    "        if model_first_name == 'regsification_BERT':\n",
    "            nn_regsif_bert.load_state_dict(torch.load(f'models/{model_name}'))\n",
    "            models[model_first_name] = nn_regsif_bert.to('cpu').eval()\n",
    "\n",
    "print('All models loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "sbert_model_name = 'paraphrase-MiniLM-L6-v2'\n",
    "device = 'cuda'\n",
    "sbert = SentenceTransformer(sbert_model_name, device=device)\n",
    "\n",
    "def embed_text_openai(text, model=\"text-embedding-ada-002\"):\n",
    "    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "    text = str(text).replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def embed_text_BERT(text, emb_model=sbert):\n",
    "    embeddings = emb_model.encode(text, convert_to_tensor=True).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "def inverse_transform_prediction(normalized_prediction, min_val= 0.0, max_val=18563.0):\n",
    "    raw_prediction = normalized_prediction * (max_val - min_val) + min_val\n",
    "    return raw_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text, model_name, emb_type):\n",
    "    if emb_type == 'openai':\n",
    "        emb = embed_text_openai(text)\n",
    "    elif emb_type == 'bert':\n",
    "        emb = embed_text_BERT(text)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown embedding type: {emb_type}')\n",
    "    \n",
    "    if model_name in ml_model_names:\n",
    "        model = models[model_name]\n",
    "        pred = model.predict([emb])[0]\n",
    "        return pred\n",
    "    elif model_name in dl_model_names:\n",
    "        if 'classification' in model_name:\n",
    "            model = models[model_name]\n",
    "            emb = torch.tensor(emb).float().to('cpu')\n",
    "            outputs = model(emb)\n",
    "            _, predicted = torch.max(outputs.data, 0)\n",
    "            pred = predicted.item()\n",
    "            return pred\n",
    "        elif 'regression' in model_name:\n",
    "            model = models[model_name]\n",
    "            emb = torch.tensor(emb).float().to('cpu')\n",
    "            pred = model(emb).detach().cpu().numpy()[0]\n",
    "            return pred\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model name: {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Chat\n",
      "Predicted regression value: 31.27877964960868\n"
     ]
    }
   ],
   "source": [
    "text = 'the chat is very bad'\n",
    "emb_type = 'openai'\n",
    "cat_model_name = 'log_reg_classification_GPT'\n",
    "reg_model_name = 'ridge_reg_regression_GPT'\n",
    "pred_class_idx = get_prediction(text, cat_model_name, emb_type)\n",
    "pred_class_label = label_encoder_classes[pred_class_idx]\n",
    "pred_class_reg_norm = get_prediction(text, reg_model_name, emb_type)\n",
    "pred_class_reg_raw = inverse_transform_prediction(pred_class_reg_norm)\n",
    "print(f'Predicted class: {pred_class_label}')\n",
    "print(f'Predicted regression value: {pred_class_reg_raw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: IGDB\n",
      "Predicted regression value: 37.409462444484234\n"
     ]
    }
   ],
   "source": [
    "text = 'the IGDB is very bad'\n",
    "emb_type = 'openai'\n",
    "cat_model_name = 'neural_network_classification_GPT'\n",
    "reg_model_name = 'neural_network_regression_GPT'\n",
    "pred_class_idx = get_prediction(text, cat_model_name, emb_type)\n",
    "pred_class_label = label_encoder_classes[pred_class_idx]\n",
    "pred_class_reg_norm = get_prediction(text, reg_model_name, emb_type)\n",
    "pred_class_reg_raw = inverse_transform_prediction(pred_class_reg_norm)\n",
    "print(f'Predicted class: {pred_class_label}')\n",
    "print(f'Predicted regression value: {pred_class_reg_raw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
